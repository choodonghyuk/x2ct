# X-ray to CT Reconstruction with ZeroRF Deep Image Prior

**í”„ë¡œì íŠ¸ ëª©í‘œ**: ZeroRFì˜ TensoRF-VM ì•„í‚¤í…ì²˜ì™€ Deep Image Priorë¥¼ í™œìš©í•˜ì—¬ Sparse-view X-ray to CT Reconstruction ëª¨ë¸ ê°œë°œ

**ì‘ì„±ì¼**: 2026ë…„ 2ì›” 16ì¼

---

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”

### í•µì‹¬ ì•„ì´ë””ì–´
- **ZeroRF ìœ ì§€**: TensoRF-VM representation + Deep Image Prior (ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ ìì—°ìŠ¤ëŸ¬ìš´ 3D í˜•ìƒì˜ prior ì—­í• )
- **NAF ì°¸ê³ **: X-ray ë°ì´í„° ë¡œë”©, Beer-Lambert law ê¸°ë°˜ attenuation ë Œë”ë§, CBCT geometry
- **ì‘ì—… ë³€ê²½**: Natural image novel view synthesis â†’ X-ray to CT reconstruction

### í•µì‹¬ ì„¤ê³„ ì›ì¹™
1. **View-Agnostic Architecture**: ë°ì´í„°ì…‹ì—ì„œ ìë™ìœ¼ë¡œ view ìˆ˜ì™€ í•´ìƒë„ ê°ì§€
2. **Data-Driven Configuration**: ë°ì´í„° ê²½ë¡œë§Œ ë³€ê²½í•˜ë©´ ì¦‰ì‹œ ì‹¤í–‰ (10/50/100 views ëª¨ë‘ ê°€ëŠ¥)
3. **Per-Scene Optimization**: ê° CT scanë§ˆë‹¤ ë…ë¦½ì ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ìµœì í™” (ZeroRF ë°©ì‹)

---

## ğŸ¯ ì£¼ìš” ë³€ê²½ì‚¬í•­

### ì•„í‚¤í…ì²˜ ë¹„êµ

| êµ¬ì„± ìš”ì†Œ | ZeroRF (ì›ë³¸) | ì´ í”„ë¡œì íŠ¸ |
|---------|--------------|------------|
| **ì…ë ¥** | RGB ì´ë¯¸ì§€ (ìì—° ì˜ìƒ) | X-ray projections |
| **ì¶œë ¥** | RGB + Density | Attenuation coefficient (Î¼) |
| **Representation** | TensoRF-VM (6 components) | TensoRF-VM (ë™ì¼ ìœ ì§€) |
| **Rendering** | Volume rendering (TÂ·Î±Â·RGB) | Beer-Lambert integration (Î£Î¼Â·Î´t) |
| **Camera** | Pinhole (intrinsics) | Cone-beam (source-detector) |
| **í•™ìŠµ ë°©ì‹** | Per-scene from noise | Per-scene from noise (ë™ì¼) |
| **Encoder** | Deep Image Prior (noiseâ†’VAE) | Deep Image Prior (ë™ì¼ ìœ ì§€) |
| **Ray sampling** | 4Kâ†’65K curriculum | 4Kâ†’65K curriculum (ë™ì¼) |
| **Iterations** | 10000 | 10000 (ë™ì¼) |

### ZeroRFì—ì„œ ìœ ì§€í•  ê²ƒ (ë³€ê²½ ì—†ìŒ)
- âœ… **TensoRF-VM Representation**: Noise â†’ VAE â†’ VM components (3 planes + 3 lines)
- âœ… **Feature ì¶”ì¶œ**: `get_point_code()` - 3D ì¢Œí‘œì—ì„œ VM feature ìƒ˜í”Œë§
- âœ… **MLP í•™ìŠµ**: `CommonDecoder` - Point feature â†’ MLP â†’ ì¶œë ¥
- âœ… **Deep Image Prior**: ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê°€ 3D prior ì—­í• 
- âœ… **Per-scene optimization**: ê° scanë§ˆë‹¤ ë…ë¦½ í•™ìŠµ
- âœ… **Curriculum learning**: Ray batch 4096 â†’ 65536 ì ì§„ì  ì¦ê°€ (100 iter í›„)

### NAFì—ì„œ ê°€ì ¸ì˜¬ ê²ƒ
- âœ… X-ray ë°ì´í„° ë¡œë” (`src/dataset/tigre.py` - `ConeGeometry`, `get_rays()`)
- âœ… Attenuation ê³„ì‚° ë¡œì§ (`src/render/render.py` - Beer-Lambert law)
- âœ… Projection space loss (`src/loss/loss.py` - MSE)
- âŒ Hash encoder ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ZeroRFì˜ Deep Prior ìœ ì§€)
- âŒ NAF ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ

### ì‹¤ì œ ë³€ê²½ì‚¬í•­ì€ ì˜¤ì§
- ğŸ”„ **MLP ì¶œë ¥ í—¤ë“œ**: RGB (3 channels) â†’ Attenuation (1 channel)
- ğŸ”„ **ë Œë”ë§ ë°©ì •ì‹**: Volume rendering â†’ Beer-Lambert integration
- ğŸ”„ **ë°ì´í„° ì…ë ¥**: Natural images â†’ X-ray projections

### âš™ï¸ ì¤‘ìš”í•œ í•™ìŠµ ì „ëµ (ZeroRF ê·¸ëŒ€ë¡œ ìœ ì§€)

**ì™œ Ray ìˆ˜ë¥¼ ì¦ê°€ì‹œí‚¤ëŠ”ê°€?**
- **ì´ˆê¸° (4K rays)**: ë¹ ë¥¸ global structure í•™ìŠµ
- **í›„ê¸° (65K rays)**: ì„¸ë°€í•œ detail í•™ìŠµ
- **ì›ë¦¬**: Coarse-to-fine curriculum learning

**ì™œ 10000 iterationsì¸ê°€?**
- **Deep Priorì˜ íŠ¹ì„±**: Random noiseë¶€í„° ì‹œì‘í•˜ì—¬ 3D structureë¥¼ "ë°œê²¬"í•´ì•¼ í•¨
- **NAFì™€ ì°¨ì´**: NAFëŠ” explicit encoding (hash grid) ì‚¬ìš© â†’ ë¹ ë¥¸ ìˆ˜ë ´ (1000 epoch)
- **ZeroRF**: Implicit prior (network structure) â†’ ëŠë¦° ìˆ˜ë ´ (10K iters) but ë” ê°•í•œ ì¼ë°˜í™”

**GPU ë©”ëª¨ë¦¬ ê³ ë ¤ì‚¬í•­** (ëª¨ë¸ + í•™ìŠµ í¬í•¨):
- 65K rays: **24GB+ GPU í•„ìš”** (RTX 4090, A6000)
- 32K rays: **20-22GB GPU** (RTX 3090Ti)
- 16K rays: **14-16GB GPU** (RTX 4070Ti, RTX 3080) â­ ê¶Œì¥
- 8K rays: **8-12GB GPU** (RTX 3070)

| GPU ë©”ëª¨ë¦¬ | n_rays_init | n_rays_up | ì˜ˆìƒ VRAM | ëª¨ë¸ í¬í•¨ |
|-----------|-------------|-----------|-----------|----------|
| **24GB+** | 4096 | 65536 | ~22 GB | Safe |
| **22GB** | 4096 | 32768 | ~18 GB | Safe |
| **16GB** â­ | **2048** | **16384** | **~12 GB** | **Safe** |
| **12GB** | 2048 | 8192 | ~9 GB | Tight |

---

## ğŸ”§ êµ¬í˜„ ê³„íš

### Phase 1: ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### 1.1 X-ray Dataset Adapter ìƒì„±
**íŒŒì¼ ìœ„ì¹˜**: `zerorf/lib/datasets/xray_dataset.py` (ì‹ ê·œ ìƒì„±)

**ê¸°ëŠ¥**:
- NAFì˜ `TIGREDataset` ê¸°ë°˜ X-ray ë°ì´í„° ë¡œë”©
- **ìë™ ê°ì§€**:
  ```python
  self.n_views = len(projection_files)  # view ìˆ˜ ìë™ ì¹´ìš´íŠ¸
  self.image_h, self.image_w = projs[0].shape  # í•´ìƒë„ ìë™ ê°ì§€
  ```
- Cone-beam geometry íŒŒë¼ë¯¸í„° ë¡œë“œ (DSD, DSO, detector size)
- NAF í˜•ì‹ â†’ ZeroRF í˜•ì‹ ë³€í™˜

**ì°¸ê³  íŒŒì¼**:
- NAF: `naf_cbct/src/dataset/tigre.py` (L13-L287)
  - `ConeGeometry` class (L13-59)
  - `get_rays()` method (L195-234)

**ì¶œë ¥ í˜•ì‹**:
```python
{
    'cond_imgs': (1, N, H, W, 1),      # X-ray projections (Nì€ ìë™ ê°ì§€)
    'cond_poses': (1, N, 4, 4),        # Equivalent pose matrices
    'cond_intrinsics': (1, N, 4),      # Cone-beamìœ¼ë¡œë¶€í„° íŒŒìƒ
    'scene_id': [0],
    'scene_name': ['scan_name']
}
```

#### 1.2 Dataset Builder ë“±ë¡
**íŒŒì¼ ìˆ˜ì •**: `zerorf/lib/datasets/builder.py`
- `XrayDataset` import ì¶”ê°€
- Dataset type ë“±ë¡

---

### Phase 2: Beer-Lambert ë Œë”ë§ êµ¬í˜„

#### 2.1 CUDA ì»¤ë„ êµ¬í˜„: `composite_rays_xray()`
**íŒŒì¼ ìœ„ì¹˜**: `zerorf/lib/ops/raymarching/` (CUDA extension)

**ë Œë”ë§ ë°©ì •ì‹ ë³€ê²½**:
```cpp
// ê¸°ì¡´ (Volume Rendering):
// alpha_i = 1 - exp(-sigma_i * dt)
// T_i = prod(1 - alpha_j) for j < i
// RGB = sum(T_i * alpha_i * color_i)

// ì‹ ê·œ (X-ray Attenuation - Beer-Lambert Law):
// I = I_0 * exp(-âˆ«Î¼(x)dx)
// For discrete sampling: projection = sum(mu_i * dt_i)
// ì§ì ‘ ì ë¶„, transmittance ê³„ì‚° ì—†ìŒ
```

**Beer-Lambert Law êµ¬í˜„ (Python)**:

NAF ì°¸ê³ : `naf_cbct/src/render/render.py` (L73-96)
```python
def composite_rays_xray(mu, z_vals, rays_d):
    """
    X-ray attenuation line integral (Beer-Lambert law)
    
    Args:
        mu: [M] Attenuation coefficients (Î¼) from network
        z_vals: [N, n_samples] Sample positions along rays
        rays_d: [N, 3] Ray directions
    
    Returns:
        projection: [N] Accumulated attenuation per ray
    """
    # 1. Calculate path lengths (Î´t)
    dists = z_vals[..., 1:] - z_vals[..., :-1]  # [N, n_samples-1]
    
    # Append small value for last segment
    dists = torch.cat([
        dists, 
        torch.ones_like(dists[..., :1]) * 1e-10
    ], dim=-1)  # [N, n_samples]
    
    # Account for ray direction (actual 3D distance)
    dists = dists * torch.norm(rays_d[..., None, :], dim=-1)  # [N, n_samples]
    
    # 2. Beer-Lambert line integral: âˆ«Î¼(x)dx â‰ˆ Î£(Î¼_i * Î´t_i)
    # mu shape: [M] where M = N * n_samples (flattened)
    # Reshape to [N, n_samples]
    mu_reshaped = mu.reshape(z_vals.shape[0], z_vals.shape[1])
    
    # 3. Sum along ray: projection = Î£(Î¼_i * Î´t_i)
    projection = torch.sum(mu_reshaped * dists, dim=-1)  # [N]
    
    return projection
```

**í•µì‹¬ ì°¨ì´ì **:
```python
# Volume Rendering (ZeroRF ê¸°ì¡´):
alpha = 1.0 - torch.exp(-sigma * dists)  # Absorption
T = torch.cumprod(1.0 - alpha + 1e-10, dim=-1)  # Transmittance
rgb = torch.sum(T * alpha * color, dim=-1)  # Accumulated color

# X-ray Attenuation (ì‹ ê·œ):
projection = torch.sum(mu * dists, dim=-1)  # Direct line integral
# No exponential, No transmittance, No color
```

**CUDA ì»¤ë„ êµ¬í˜„ (Pseudo-code)**:

íŒŒì¼: `zerorf/lib/ops/raymarching/raymarching.cu`
```cpp
__global__ void composite_rays_xray_kernel(
    const float* __restrict__ mu,        // [M] Attenuation coefficients
    const float* __restrict__ ts,        // [M, 2] t_start, t_end per sample
    const int* __restrict__ rays,        // [N, 2] ray_idx, n_samples
    float* __restrict__ projection,      // [N] Output projections
    const int M,
    const int N
) {
    const int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= M) return;
    
    // Get ray index for this sample
    const int ray_idx = rays[i * 2];
    
    // Calculate path length
    const float dt = ts[i * 2 + 1] - ts[i * 2];
    
    // Accumulate: projection += Î¼ * Î´t
    atomicAdd(&projection[ray_idx], mu[i] * dt);
}

// Wrapper function
void composite_rays_xray(
    at::Tensor mu,           // [M] from network
    at::Tensor ts,           // [M, 2] sample intervals
    at::Tensor rays,         // [N, 2] ray metadata
    at::Tensor projection    // [N] output
) {
    const int M = mu.size(0);
    const int N = projection.size(0);
    
    // Initialize projection to zero
    projection.fill_(0.0f);
    
    // Launch kernel
    const int threads = 256;
    const int blocks = (M + threads - 1) / threads;
    
    composite_rays_xray_kernel<<<blocks, threads>>>(
        mu.data_ptr<float>(),
        ts.data_ptr<float>(),
        rays.data_ptr<int>(),
        projection.data_ptr<float>(),
        M, N
    );
}
```

**ì°¸ê³ **:
- ê¸°ì¡´ êµ¬í˜„: `zerorf/lib/ops/raymarching/raymarching.py` - `composite_rays_train()` (L330-380)
- NAF ë¡œì§: `naf_cbct/src/render/render.py` - `raw2outputs()` (L96)
  ```python
  acc = torch.sum((raw[..., 0] + noise) * dists, dim=-1)
  ```

#### 2.2 Base Volume Renderer ìˆ˜ì •
**íŒŒì¼ ìˆ˜ì •**: `zerorf/lib/models/decoders/base_volume_renderer.py`

**ë³€ê²½ì‚¬í•­**:
- `__init__()`: `xray_mode` íŒŒë¼ë¯¸í„° ì¶”ê°€
- `forward()` (L205-370):
  ```python
  class VolumeRenderer(nn.Module):
      def __init__(self, *args, xray_mode=False, **kwargs):
          super().__init__(*args, **kwargs)
          self.xray_mode = xray_mode
      
      def forward(self, rays_o, rays_d, code, density_bitfield, ...):
          # 1. Ray marching (ë™ì¼)
          xyzs, dirs, ts, rays = march_rays_train(
              rays_o, rays_d, density_bitfield, ...)
          
          # 2. Network forward: 3D points â†’ attenuation
          point_code = self.get_point_code(code, xyzs)
          
          if self.xray_mode:
              # X-ray: Only density (attenuation)
              mu, _ = self.point_code_render(point_code, dirs=None)
              # mu: [M] attenuation coefficients
          else:
              # RGB: Density + Color
              sigma, rgb = self.point_code_render(point_code, dirs)
          
          # 3. Rendering
          if self.xray_mode:
              # Beer-Lambert line integral
              projection = composite_rays_xray(
                  mu, ts, rays)  # [N]
              outputs = {
                  'projection': projection,  # [N]
                  'depth': None,  # Optional: can compute depth
                  'weights': None  # Optional: for importance sampling
              }
          else:
              # Volume rendering
              weights, depth, rgb_out = composite_rays_train(
                  sigma, rgb, ts, rays, ...)
              outputs = {
                  'image': rgb_out.reshape(H, W, 3),
                  'depth': depth.reshape(H, W),
                  'weights': weights
              }
          
          return outputs
  ```

**í†µí•© ì˜ˆì‹œ (forward ì „ì²´)**:
```python
def forward(self, rays_o, rays_d, code, density_bitfield, 
            grid_size, dt_gamma=0, perturb=False):
    """
    Args:
        rays_o: [N, 3] Ray origins
        rays_d: [N, 3] Ray directions
        code: Scene code from TensorialGenerator
        
    Returns (X-ray mode):
        outputs = {
            'projection': [N] Accumulated attenuation,
            'depth': [N] Average depth (optional),
            'weights': [N, n_samples] For importance sampling (optional)
        }
    """
    N = rays_o.shape[0]
    
    # === Step 1: Ray Marching ===
    xyzs, dirs, ts, rays_info = march_rays_train(
        rays_o, rays_d, 
        bound=self.bound,
        density_bitfield=density_bitfield,
        grid_size=grid_size,
        nears=None, fars=None,
        dt_gamma=dt_gamma, perturb=perturb,
        max_steps=self.max_steps
    )
    # xyzs: [M, 3] Sampled 3D points
    # ts: [M, 2] t_start, t_end for each sample
    # rays_info: [N, 2] (ray_idx, n_samples)
    # M = total samples across all rays
    
    # === Step 2: Feature Extraction (TensoRF-VM) ===
    point_code = self.get_point_code(code, xyzs)
    # point_code: [M, in_chs] from VM grids
    
    # === Step 3: MLP Decoding ===
    if self.xray_mode:
        # X-ray: Attenuation only
        mu, _ = self.point_code_render(point_code, dirs=None)
        # mu: [M] attenuation coefficients
    else:
        # RGB: Density + Color
        sigma, rgb = self.point_code_render(point_code, dirs)
    
    # === Step 4: Rendering ===
    if self.xray_mode:
        # Calculate path lengths
        dists = ts[:, 1] - ts[:, 0]  # [M]
        
        # Beer-Lambert integral
        projection = torch.zeros(N, device=mu.device)
        for i in range(M):
            ray_idx = rays_info[i, 0]
            projection[ray_idx] += mu[i] * dists[i]
        
        # Or use scatter_add for efficiency
        # projection = scatter_add(mu * dists, rays_info[:, 0], dim=0, dim_size=N)
        
        outputs = {'projection': projection}
    else:
        # Standard volume rendering
        weights, depth, rgb_final = composite_rays_train(
            sigma, rgb, ts, rays_info, ...)
        outputs = {'image': rgb_final, 'depth': depth, 'weights': weights}
    
    return outputs
```

---

### Phase 3: ë„¤íŠ¸ì›Œí¬ ì¶œë ¥ ìˆ˜ì •

#### 3.1 CommonDecoder ìˆ˜ì • (Attenuation Only)
**íŒŒì¼ ìˆ˜ì •**: `zerorf/lib/models/zerorf/decoders.py` (L60-L139)

**ë³€ê²½ì‚¬í•­**:
```python
class CommonDecoder(nn.Module):
    def __init__(self, point_channels, sh_coef_only=False, dir_pe=False, 
                 sdf_mode=False, xray_mode=False):
        super().__init__()
        self.xray_mode = xray_mode
        
        # Base network + Density network (ìœ ì§€)
        self.base_net = nn.Linear(point_channels, 64)
        self.density_net = nn.Sequential(nn.Linear(64, 1), TruncExp())
        
        # X-ray ëª¨ë“œ: Color network ë¹„í™œì„±í™”
        if xray_mode:
            self.dir_net = None
            self.color_net = None
        else:
            self.dir_encoder = SHEncoder(degree=3)
            self.dir_net = nn.Linear(9, 64)
            self.color_net = nn.Sequential(nn.Linear(64, 3), nn.Sigmoid())
    
    def forward(self, point_code, dirs=None, out_sdf=False):
        base_x_act = self.base_activation(self.base_net(point_code))
        sigmas = self.density_net(base_x_act).squeeze(-1)  # Attenuation
        
        if self.xray_mode:
            return sigmas, None  # RGB ì—†ìŒ
        else:
            # RGB ê³„ì‚° (ê¸°ì¡´ ë¡œì§)
            ...
            return sigmas, rgbs
```

#### 3.2 TensorialDecoder íŒŒë¼ë¯¸í„° ì „ë‹¬
**íŒŒì¼ ìˆ˜ì •**: `zerorf/lib/models/zerorf/decoders.py` (L145)

**ë³€ê²½ì‚¬í•­**:
- `__init__()` í˜¸ì¶œ ì‹œ `xray_mode=True` ì „ë‹¬
- `n_images`, `image_h`, `image_w`: ë°ì´í„°ì…‹ì—ì„œ ìë™ ê°ì§€ëœ ê°’ ì‚¬ìš©
- `separate_density_and_color=False` ìœ ì§€

---

### Phase 4: í•™ìŠµ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

#### 4.1 Main Script ìˆ˜ì •
**íŒŒì¼ ìˆ˜ì •**: `zerorf/zerorf.py` (ë˜ëŠ” ì‹ ê·œ `xray_train.py` ìƒì„±)

**ë°ì´í„° ë¡œë”© ë¶€ë¶„** (L60-120 ì°¸ê³ ):
```python
# Dataset ë¨¼ì € ë¡œë“œ (ìë™ ê°ì§€)
if args.dataset == "xray":
    dataset = XrayDataset(args.data_dir, split='train')
    val_dataset = XrayDataset(args.data_dir, split='val')
    
    # ìë™ ê°ì§€ëœ íŒŒë¼ë¯¸í„° ì¶œë ¥
    n_views = dataset.n_views
    image_h, image_w = dataset.image_h, dataset.image_w
    print(f"âœ“ Auto-detected: {n_views} views, {image_h}Ã—{image_w} resolution")

# Data entry êµ¬ì„±
data_entry = dict(
    cond_imgs=dataset[0]['cond_imgs'],      # (1, N, H, W, 1)
    cond_poses=dataset[0]['cond_poses'],    # (1, N, 4, 4)
    cond_intrinsics=dataset[0]['cond_intrinsics'],  # (1, N, 4)
    scene_id=[0],
    scene_name=[args.data_dir.split('/')[-1]]
)
```

**Decoder êµ¬ì„±** (L142-152 ì°¸ê³ ):
```python
decoder_1 = dict(
    type='TensorialDecoder',
    preprocessor=dict(
        type='TensorialGenerator',
        in_ch=args.model_ch,
        out_ch=16,
        noise_res=args.model_res,
        tensor_config=['xy', 'z', 'yz', 'x', 'zx', 'y']  # TensoRF-VM
    ),
    subreduce=1,
    reduce='cat',
    separate_density_and_color=False,
    sh_coef_only=False,
    sdf_mode=False,
    xray_mode=True,           # âœ“ X-ray ëª¨ë“œ í™œì„±í™”
    n_images=n_views,         # âœ“ ìë™ ê°ì§€ëœ ê°’
    image_h=image_h,          # âœ“ ìë™ ê°ì§€ëœ ê°’
    image_w=image_w,          # âœ“ ìë™ ê°ì§€ëœ ê°’
    max_steps=1024,
)
```

#### 4.2 Training Loop
**ì°¸ê³ **: `zerorf.py` (L230-275), `naf_cbct/train.py`

**í•™ìŠµ ë°©ì‹**:
- Per-scene optimization (ZeroRF ë°©ì‹)
- Ray-based sampling (view ìˆ˜ ë¬´ê´€)
- Hierarchical sampling (coarse + fine)

**Hyperparameters** (ZeroRF ê¸°ë°˜, 16GB GPU ìµœì í™”):
```yaml
train:
  n_iters: 10000            # Total iterations (ZeroRF ì‚¬ìš©)
  n_rays_init: 2048         # 2^11: Ray batch size (ì´ˆê¸°)
  n_rays_up: 16384          # 2^14: Ray batch size (100 iter í›„) - 16GB GPU ê¶Œì¥
  ray_upsample_iter: 100    # Ray curriculum learning
  lrate: 0.002              # AdamW learning rate
  lrate_decay: cosine
  
render:
  n_samples: 256            # Coarse sampling
  n_fine: 256               # Fine sampling (hierarchical)
  perturb: True
```

**Note**: 
- ZeroRFëŠ” ray ìˆ˜ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ëŠ” curriculum learning ì‚¬ìš©
- 16GB GPU: 16K rays ê¶Œì¥ (~12GB VRAM, ëª¨ë¸ í¬í•¨ ì•ˆì „)
- 22GB+ GPU: 32K rays ê°€ëŠ¥
- 24GB+ GPU: 65K rays ê°€ëŠ¥ (ì›ë³¸ ZeroRF ì„¤ì •)

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
# Ray curriculum learning (ZeroRF ë°©ì‹, 16GB GPU ìµœì í™”)
for iteration in range(args.n_iters):
    # Ray ìˆ˜ ì ì§„ì  ì¦ê°€
    if iteration <= args.ray_upsample_iter:
        n_rays = args.n_rays_init  # 2048
    else:
        n_rays = args.n_rays_up     # 16384 (16GB) or 32768 (22GB+)
    
    # Random ray sampling (view ìˆ˜ ë¬´ê´€)
    rays_batch = sample_rays(all_rays, n_rays)
    
    # Hierarchical rendering
    outputs = render(rays_batch, net, net_fine,
                    n_samples=256, n_importance=256)
    
    # Loss & backward
    loss = F.mse_loss(outputs['projection'], target)
    loss.backward()
    optimizer.step()
```

#### 4.3 Loss Function
**íŒŒì¼ ìˆ˜ì •**: `zerorf/lib/models/autoencoders/multiscene_nerf.py` (L200-258)

**Loss ê³„ì‚°**:
```python
def compute_loss(self, data, outputs):
    """
    X-ray projection loss
    
    Args:
        data: {
            'target_proj': [N, H, W] Ground truth X-ray projections
            'rays': [N, H, W, 8] Ray parameters
        }
        outputs: {
            'projection': [N*H*W] Predicted projections (flattened)
        }
    
    Returns:
        loss_dict: {'loss': total_loss, 'proj_mse': mse, 'psnr': psnr}
    """
    # 1. Reshape predictions
    target_proj = data['target_proj'].reshape(-1)  # [N*H*W]
    pred_proj = outputs['projection']  # [N*H*W]
    
    # 2. Projection space MSE (main loss)
    loss_mse = F.mse_loss(pred_proj, target_proj)
    
    # 3. Optional: L1 loss for sparsity
    # loss_l1 = F.l1_loss(pred_proj, target_proj)
    
    # 4. Optional: Total Variation Regularization (3D volume)
    # if self.use_tv_reg:
    #     volume = self.reconstruct_volume(code)
    #     loss_tv = self.calc_tv_loss(volume)
    # else:
    #     loss_tv = 0.0
    
    # 5. Total loss
    total_loss = loss_mse  # + 0.1 * loss_l1 + 0.01 * loss_tv
    
    # 6. Compute PSNR for monitoring
    with torch.no_grad():
        mse_value = loss_mse.item()
        psnr = -10 * np.log10(mse_value) if mse_value > 0 else 100.0
    
    loss_dict = {
        'loss': total_loss,
        'proj_mse': loss_mse,
        'psnr': torch.tensor(psnr)
    }
    
    return loss_dict


# NAF ì°¸ê³ : src/loss/loss.py
def calc_mse_loss(loss_dict, target, pred):
    """Simple MSE loss (NAF style)"""
    mse = torch.mean((target - pred) ** 2)
    loss_dict['mse'] = mse
    loss_dict['loss'] += mse
    return loss_dict


# Optional: Total Variation Loss
def calc_tv_loss(volume):
    """
    3D Total Variation for smoothness
    
    Args:
        volume: [D, H, W] 3D reconstructed CT volume
    
    Returns:
        tv_loss: Scalar
    """
    # Gradient in x, y, z directions
    diff_x = torch.abs(volume[1:, :, :] - volume[:-1, :, :])
    diff_y = torch.abs(volume[:, 1:, :] - volume[:, :-1, :])
    diff_z = torch.abs(volume[:, :, 1:] - volume[:, :, :-1])
    
    tv_loss = diff_x.mean() + diff_y.mean() + diff_z.mean()
    return tv_loss
```

**Training Loopì—ì„œ ì‚¬ìš©**:
```python
for iteration in range(args.n_iters):
    # Sample rays
    rays_batch = sample_rays(all_rays, n_rays)
    target_batch = sample_projections(all_projs, n_rays)
    
    # Forward pass
    outputs = model(rays_batch['rays_o'], rays_batch['rays_d'], 
                    code, density_bitfield)
    # outputs['projection']: [n_rays]
    
    # Compute loss
    loss_dict = compute_loss(
        data={'target_proj': target_batch},
        outputs=outputs
    )
    
    # Backward
    optimizer.zero_grad()
    loss_dict['loss'].backward()
    optimizer.step()
    
    # Logging
    if iteration % 100 == 0:
        print(f"Iter {iteration}, Loss: {loss_dict['loss'].item():.6f}, "
              f"PSNR: {loss_dict['psnr'].item():.2f} dB")
```

---

### Phase 5: í‰ê°€ ë° ê²€ì¦

#### 5.1 Evaluation Metrics
**ì°¸ê³ **: `naf_cbct/train.py` (L47-73)

**Projection Space**:
- PSNR (2D)
- SSIM (2D)

**Volume Space**:
- 3D PSNR
- 3D SSIM
- Visual comparison (slice views)

#### 5.2 Visualization
- Rendered projections vs Ground truth
- Reconstructed CT slices (axial, coronal, sagittal)
- TensorBoard logging

---

## ğŸ“ êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: Data Pipeline
- [ ] `lib/datasets/xray_dataset.py` ìƒì„±
  - [ ] `ConeGeometry` í´ë˜ìŠ¤ í†µí•©
  - [ ] `get_rays()` ë©”ì„œë“œ êµ¬í˜„
  - [ ] View ìˆ˜/í•´ìƒë„ ìë™ ê°ì§€
  - [ ] ZeroRF í˜•ì‹ ë³€í™˜
- [ ] `lib/datasets/builder.py` ìˆ˜ì • (dataset ë“±ë¡)
- [ ] Unit test: 10/50/100 views ë°ì´í„° ë¡œë“œ í…ŒìŠ¤íŠ¸

### Phase 2: Rendering
- [ ] `lib/ops/raymarching/` Beer-Lambert ë Œë”ë§ êµ¬í˜„
  - [ ] `composite_rays_xray()` Python í•¨ìˆ˜ ì‘ì„±
    - [ ] Path length ê³„ì‚°: `dists = z_vals[1:] - z_vals[:-1]`
    - [ ] Line integral: `projection = sum(mu * dists)`
    - [ ] Shape í™•ì¸: `mu [M]` â†’ `projection [N]`
  - [ ] CUDA ì»¤ë„ ì‘ì„± (ì„±ëŠ¥ ìµœì í™”)
    - [ ] `composite_rays_xray_kernel` êµ¬í˜„
    - [ ] `atomicAdd` ë˜ëŠ” `scatter_add` ì‚¬ìš©
  - [ ] ìˆ˜ì‹ ê²€ì¦: âˆ«Î¼(x)dx â‰ˆ Î£(Î¼_i * Î´t_i)
  - [ ] Gradient ê³„ì‚° í™•ì¸ (backward pass)
  - [ ] Unit test: ì˜ˆìƒê°’ê³¼ ë¹„êµ
- [ ] `lib/models/decoders/base_volume_renderer.py` í†µí•©
  - [ ] `__init__()`: `xray_mode` íŒŒë¼ë¯¸í„° ì¶”ê°€
  - [ ] `forward()`:
    - [ ] X-ray mode ë¶„ê¸° ì²˜ë¦¬
    - [ ] `composite_rays_xray()` í˜¸ì¶œ
    - [ ] ì¶œë ¥ í˜•ì‹: `{'projection': [N]}`
  - [ ] Volume renderingê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸
- [ ] Unit test: End-to-end rendering
  - [ ] Single ray â†’ expected projection
  - [ ] Batch rays â†’ consistent results
  - [ ] Gradient flow í™•ì¸

### Phase 3: Network
- [ ] `lib/models/zerorf/decoders.py` ìˆ˜ì •
  - [ ] `CommonDecoder`: `xray_mode` ì¶”ê°€
  - [ ] Color network ë¹„í™œì„±í™” ë¡œì§
  - [ ] Forward pass ìˆ˜ì •
- [ ] `TensorialDecoder` íŒŒë¼ë¯¸í„° ì „ë‹¬ í™•ì¸
- [ ] Unit test: ì¶œë ¥ shape (N, 1) í™•ì¸

### Phase 4: Training
- [ ] `zerorf.py` ë˜ëŠ” `xray_train.py` ìƒì„±
  - [ ] Dataset ìë™ ê°ì§€ ë¡œì§
  - [ ] Decoder config êµ¬ì„±
  - [ ] Training loop êµ¬í˜„
- [ ] Config íŒŒì¼ ìƒì„± (`configs/xray.yaml`)
- [ ] Loss function í†µí•©
- [ ] TensorBoard logging ì„¤ì •

### Phase 5: Evaluation
- [ ] Evaluation script ì‘ì„±
- [ ] Metrics ê³„ì‚° (PSNR, SSIM)
- [ ] Visualization ì½”ë“œ
- [ ] ê²°ê³¼ ë¹„êµ (NAF ë‹¨ë… vs ZeroRF+X-ray)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê³„íš

### 1. Unit Tests
```bash
# ë°ì´í„° ë¡œë”©
python -c "from lib.datasets.xray_dataset import XrayDataset; \
    ds = XrayDataset('./data/test_10views'); \
    print(f'Views: {ds.n_views}, Size: {ds.image_h}x{ds.image_w}')"

# Beer-Lambert law ê²€ì¦
pytest tests/test_xray_rendering.py::test_beer_lambert

# ë Œë”ë§ (ë‹¨ì¼ ray)
pytest tests/test_xray_rendering.py::test_single_ray

# ë„¤íŠ¸ì›Œí¬ forward
pytest tests/test_xray_network.py::test_attenuation_output
```

**Beer-Lambert Law Unit Test ì˜ˆì‹œ**:

íŒŒì¼: `tests/test_xray_rendering.py`
```python
import torch
import pytest
from lib.ops.raymarching import composite_rays_xray

def test_beer_lambert():
    """
    Beer-Lambert law ê²€ì¦:
    Uniform attenuation â†’ Expected projection
    """
    # Setup: Uniform attenuation coefficient
    n_rays = 10
    n_samples = 100
    mu_value = 0.5  # Uniform Î¼ = 0.5
    
    # Ray samples
    z_vals = torch.linspace(0, 1, n_samples).repeat(n_rays, 1)  # [N, n_samples]
    rays_d = torch.tensor([[0, 0, 1]]).repeat(n_rays, 1).float()  # [N, 3]
    
    # Attenuation coefficients
    mu = torch.ones(n_rays * n_samples) * mu_value  # [M]
    
    # Expected: âˆ«Î¼dx = Î¼ * length = 0.5 * 1.0 = 0.5
    expected_projection = mu_value * 1.0
    
    # Compute
    projection = composite_rays_xray(mu, z_vals, rays_d)  # [N]
    
    # Verify
    assert projection.shape == (n_rays,)
    assert torch.allclose(projection, torch.tensor(expected_projection), atol=1e-4)
    print(f"âœ“ Beer-Lambert test passed: {projection[0]:.4f} â‰ˆ {expected_projection:.4f}")


def test_single_ray_gradient():
    """
    Gradient flow í™•ì¸
    """
    n_samples = 50
    z_vals = torch.linspace(0, 1, n_samples).unsqueeze(0)  # [1, n_samples]
    rays_d = torch.tensor([[0, 0, 1]]).float()
    
    # Network output (requires_grad=True)
    mu = torch.ones(n_samples, requires_grad=True) * 0.3
    
    # Forward
    projection = composite_rays_xray(mu, z_vals, rays_d)
    
    # Backward
    loss = projection.sum()
    loss.backward()
    
    # Verify gradient exists
    assert mu.grad is not None
    assert not torch.isnan(mu.grad).any()
    print(f"âœ“ Gradient test passed: grad shape {mu.grad.shape}")


def test_varying_attenuation():
    """
    Variable attenuation ê²€ì¦
    """
    n_rays = 5
    n_samples = 100
    
    # Linearly increasing attenuation: Î¼(x) = x
    z_vals = torch.linspace(0, 1, n_samples).repeat(n_rays, 1)
    rays_d = torch.tensor([[0, 0, 1]]).repeat(n_rays, 1).float()
    
    mu = torch.linspace(0, 1, n_samples).repeat(n_rays)  # [M]
    
    # Expected: âˆ«x dx from 0 to 1 = 0.5
    expected_projection = 0.5
    
    projection = composite_rays_xray(mu, z_vals, rays_d)
    
    assert torch.allclose(projection, torch.tensor(expected_projection), atol=1e-2)
    print(f"âœ“ Variable attenuation test passed: {projection[0]:.4f} â‰ˆ {expected_projection:.4f}")


def test_compare_with_naf():
    """
    NAF êµ¬í˜„ê³¼ ë¹„êµ
    """
    from naf_cbct.src.render import raw2outputs
    
    # Same input
    n_rays = 20
    n_samples = 64
    raw = torch.rand(n_rays, n_samples, 1)  # NAF format
    z_vals = torch.linspace(0, 1, n_samples).repeat(n_rays, 1)
    rays_d = torch.randn(n_rays, 3)
    
    # NAF version
    naf_acc, _ = raw2outputs(raw, z_vals, rays_d)
    
    # Our version
    mu = raw.squeeze(-1).reshape(-1)  # [M]
    our_projection = composite_rays_xray(mu, z_vals, rays_d)
    
    # Should match
    assert torch.allclose(naf_acc, our_projection, atol=1e-5)
    print(f"âœ“ NAF comparison passed")


if __name__ == "__main__":
    test_beer_lambert()
    test_single_ray_gradient()
    test_varying_attenuation()
    test_compare_with_naf()
    print("\nâœ… All Beer-Lambert tests passed!")
```

### 2. Integration Test
```bash
# 10 views - Quick test (1000 iters, 16GB GPU)
python zerorf.py --dataset=xray --data-dir=./data/test_10views \
    --config=configs/xray.yaml --n-iters=1000 \
    --n-rays-init=2048 --n-rays-up=16384

# 50 views - Full training (ì½”ë“œ ìˆ˜ì • ì—†ìŒ, 16GB GPU)
python zerorf.py --dataset=xray --data-dir=./data/test_50views \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=2048 --n-rays-up=16384

# Mixed precisionìœ¼ë¡œ ë” ë§ì€ rays (20K)
python zerorf.py --dataset=xray --data-dir=./data/test_50views \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=2048 --n-rays-up=20480 \
    --use-amp
```

### 3. ì˜ˆìƒ ì¶œë ¥
```
âœ“ Auto-detected: 50 views, 512Ã—512 resolution
âœ“ TensoRF-VM initialized: 6 components (xy, z, yz, x, zx, y)
âœ“ X-ray mode enabled: Attenuation-only output
âœ“ Ray batch: 2048 â†’ 16384 (curriculum learning)
âœ“ GPU Memory: 11.8 GB / 16.0 GB (Mixed Precision: OFF)
Iter 1000/10000, Loss: 0.0028, Proj-PSNR: 27.2 dB
Iter 5000/10000, Loss: 0.0012, Proj-PSNR: 31.5 dB
Iter 10000/10000, Loss: 0.0006, Proj-PSNR: 35.2 dB
```

---

## ğŸ›ï¸ Configuration

### Example: `configs/xray.yaml`
```yaml
exp:
  datadir: "./data/abdomen_50"
  expname: "xray_ct_recon"

dataset:
  type: "xray"
  auto_detect: true  # View ìˆ˜/í•´ìƒë„ ìë™ ê°ì§€

model:
  type: "TensorialDecoder"
  xray_mode: true
  model_ch: 8
  model_res: 4
  tensor_config: ['xy', 'z', 'yz', 'x', 'zx', 'y']

train:
  n_iters: 10000              # ZeroRF ê¸°ë³¸ê°’
  n_rays_init: 2048           # ì´ˆê¸° ray batch (2^11)
  n_rays_up: 16384            # í›„ê¸° ray batch (2^14) - 16GB GPU ìµœì 
  ray_upsample_iter: 100      # Ray curriculum
  net_lr: 0.002
  net_lr_decay_to: 0.002
  optimizer: "AdamW"

render:
  n_samples: 256              # Coarse
  n_importance: 256           # Fine
  perturb: true
  max_steps: 1024

loss:
  type: "MSE"
  weight: 1.0

eval:
  val_iter: 1000              # Validate every 1000 iters
```

---

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### Training
```bash
# ê¸°ë³¸ ì‹¤í–‰ (50 views, 10000 iterations, 16GB GPU)
python zerorf.py --dataset=xray --data-dir=./data/abdomen_50 \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=2048 --n-rays-up=16384

# Sparse views (10 views) - ë™ì¼ ì½”ë“œ
python zerorf.py --dataset=xray --data-dir=./data/chest_10 \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=2048 --n-rays-up=16384

# Quick test (1000 iterations)
python zerorf.py --dataset=xray --data-dir=./data/abdomen_50 \
    --config=configs/xray.yaml --n-iters=1000 \
    --n-rays-init=2048 --n-rays-up=16384

# Mixed precisionìœ¼ë¡œ ë” ë§ì€ rays (20K rays)
python zerorf.py --dataset=xray --data-dir=./data/abdomen_50 \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=2048 --n-rays-up=20480 \
    --use-amp

# 22GB GPU ì´ìƒ (ë” ë§ì€ rays)
python zerorf.py --dataset=xray --data-dir=./data/abdomen_50 \
    --config=configs/xray.yaml --n-iters=10000 \
    --n-rays-init=4096 --n-rays-up=32768
```

### Evaluation
```bash
python evaluate_xray.py --checkpoint=results/xray_ct_recon/ckpt.pth \
    --data-dir=./data/abdomen_50 --output-dir=results/eval
```

---

## ğŸ“Š ê¸°ëŒ€ ì„±ëŠ¥

### NAF ëŒ€ë¹„ ì¥ì 
- **Sparse-view ì„±ëŠ¥**: 10-30 viewsì—ì„œ Deep Prior ë•ë¶„ì— ìš°ìˆ˜í•œ ì¬êµ¬ì„±
- **ì‚¬ì „ í•™ìŠµ ë¶ˆí•„ìš”**: ê° scanë§ˆë‹¤ ìµœì í™”
- **êµ¬ì¡°ì  prior**: TensoRF-VMì´ í•´ë¶€í•™ì  êµ¬ì¡° í‘œí˜„ì— ìœ ë¦¬

### NAF ëŒ€ë¹„ ë‹¨ì 
- **í•™ìŠµ ì‹œê°„**: Per-scene ìµœì í™”ë¡œ ì¸í•´ í•™ìŠµ ì‹œê°„ ì¦ê°€
- **Full-view ì„±ëŠ¥**: 100+ viewsì—ì„œëŠ” NAFì˜ explicit encodingì´ ìœ ë¦¬í•  ìˆ˜ ìˆìŒ

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ZeroRF
- Paper: "ZeroRF: Sparse View 360Â° Reconstruction with Zero Pretraining" (CVPR 2024)
- Code: `lib/models/zerorf/decoders.py`, `lib/models/zerorf/generators.py`
- Key: TensoRF-VM, Deep Image Prior, Per-scene optimization

### NAF (ì°¸ê³ ìš©)
- Code: `naf_cbct/src/`
- Key: X-ray geometry, Beer-Lambert law, CBCT dataset

### TensoRF
- Paper: "TensoRF: Tensorial Radiance Fields" (ECCV 2022)
- Representation: Vector-Matrix decomposition (3 planes + 3 lines)

---

## ğŸ” í•µì‹¬ ê¸°ìˆ  ê²°ì •ì‚¬í•­

### 1. Deep Image Prior ìœ ì§€ (âœ“)
- **ì´ìœ **: ZeroRFì˜ í•µì‹¬ contribution, sparse-viewì—ì„œ ê°•ë ¥
- **ëŒ€ì•ˆ**: Hash encoding (NAF) - rejected (ì‚¬ì „ í•™ìŠµ í•„ìš”, ì¼ë°˜í™” ì–´ë ¤ì›€)

### 2. TensoRF-VM ìœ ì§€ (âœ“)
- **ì´ìœ **: View-independent 3D representation, í•´ë¶€í•™ì  êµ¬ì¡° í‘œí˜„ì— ì í•©
- **ë³€ê²½ ì—†ìŒ**: RGBë“  attenuationì´ë“  feature gridëŠ” ë™ì¼

### 3. Beer-Lambert Rendering (âœ“)
- **ì´ìœ **: X-ray physicsì— ì •í™•
- **êµ¬í˜„**: Volume rendering ëŒ€ì‹  ì§ì ‘ ì ë¶„
- **í•µì‹¬ ìˆ˜ì‹**:
  ```
  Volume Rendering:  I = Î£ T_i Â· Î±_i Â· c_i
                     T_i = exp(-Î£_{j<i} Ïƒ_jÂ·Î´t_j)
                     Î±_i = 1 - exp(-Ïƒ_iÂ·Î´t_i)
  
  X-ray Attenuation: I = Î£ Î¼_i Â· Î´t_i
                     (ë‹¨ìˆœ ì„ ì ë¶„, no exponential)
  ```
- **Python êµ¬í˜„**:
  ```python
  # Volume rendering (ZeroRF ê¸°ì¡´)
  alpha = 1 - torch.exp(-sigma * dists)
  T = torch.cumprod(1 - alpha, dim=-1)
  rgb = torch.sum(T * alpha * color, dim=-1)
  
  # Beer-Lambert (X-ray)
  projection = torch.sum(mu * dists, dim=-1)
  ```
- **ì¥ì **: ë” ë‹¨ìˆœ, ë©”ëª¨ë¦¬ íš¨ìœ¨ì , X-ray physics ì •í™•
- **ê²€ì¦**: NAF êµ¬í˜„ê³¼ ì¼ì¹˜ í™•ì¸ (`raw2outputs()` L96)

### 4. View-Agnostic Design (âœ“)
- **ì´ìœ **: ì‹¤ìš©ì„±, ì‹¤í—˜ í¸ì˜ì„±
- **êµ¬í˜„**: ë°ì´í„°ì…‹ì—ì„œ ìë™ ê°ì§€

### 5. Hierarchical Sampling (âœ“)
- **ì´ìœ **: Sparse-viewì—ì„œ ì¬êµ¬ì„± í’ˆì§ˆ í–¥ìƒ
- **êµ¬í˜„**: ZeroRF ê¸°ë³¸ ì§€ì› í™œìš©

---

## âœ… Success Criteria

### Minimum Viable Product (MVP)
1. âœ“ 10/50/100 views ë°ì´í„° ìë™ ë¡œë“œ
2. âœ“ X-ray projection rendering ì •í™•ë„ ê²€ì¦
3. âœ“ Training convergence (loss ê°ì†Œ)
4. âœ“ CT volume reconstruction ì‹œê°í™”

### Performance Target
- **50 views**: Projection PSNR > 30 dB, Volume PSNR > 28 dB
- **10 views**: Projection PSNR > 25 dB (sparse-view challenge)
- **NAF ëŒ€ë¹„**: Sparse-view (10-30)ì—ì„œ ë™ë“± ì´ìƒ ì„±ëŠ¥

### Code Quality
- Unit tests í†µê³¼
- View ìˆ˜ ë³€ê²½ ì‹œ ì½”ë“œ ìˆ˜ì • ë¶ˆí•„ìš”
- Clear documentation

---

## ğŸ”§ ë©”ëª¨ë¦¬ ìµœì í™” íŒ (16GB GPU)

### 1. Mixed Precision Training (ê°•ë ¥ ê¶Œì¥)
```python
# PyTorch AMP (Automatic Mixed Precision)
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
with autocast():
    outputs = render(rays_batch, net, net_fine)
    loss = F.mse_loss(outputs['projection'], target)

scaler.scale(loss).backward()
scaler.step(optimizer)
scaler.update()
```
**ë©”ëª¨ë¦¬ ì ˆê°**: ~30-40% (16K rays â†’ 12GB ëŒ€ì‹  ~8GB)
**ì„±ëŠ¥**: ì†ë„ 10-20% í–¥ìƒ + ë©”ëª¨ë¦¬ ì ˆì•½

### 2. Gradient Checkpointing
```python
# ì¤‘ê°„ activation ì¬ê³„ì‚°ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½
from torch.utils.checkpoint import checkpoint

def forward_with_checkpoint(x):
    return checkpoint(self.network, x)
```
**ë©”ëª¨ë¦¬ ì ˆê°**: ~20-30% (ì†ë„ 10-15% ê°ì†Œ)

### 3. Ray Batch ë™ì  ì¡°ì •
```python
# OOM ë°œìƒ ì‹œ ìë™ìœ¼ë¡œ batch ê°ì†Œ
try:
    outputs = render(rays_batch, net, net_fine)
except RuntimeError as e:
    if "out of memory" in str(e):
        torch.cuda.empty_cache()
        n_rays = n_rays // 2  # Ray ìˆ˜ ì ˆë°˜ìœ¼ë¡œ
        print(f"OOM detected, reducing to {n_rays} rays")
```

### 4. ê¶Œì¥ ì¡°í•© (16GB GPU)
```yaml
# Best practice for RTX 4070Ti / RTX 3080 (16GB)
train:
  n_rays_init: 2048
  n_rays_up: 16384        # Mixed precision ì—†ì´ (ì•ˆì „)
  # or
  n_rays_up: 20480        # Mixed precision ì‚¬ìš© ì‹œ (20K rays)
  
  use_amp: true           # â­ 16GB GPUëŠ” AMP ê¶Œì¥
  gradient_checkpointing: false  # ì†ë„ ìš°ì„ 
```

### 5. ì´ˆê¸° ë©”ëª¨ë¦¬ ì²´í¬ (16GB GPU í•„ìˆ˜)
```python
# Training ì‹œì‘ ì „ ë©”ëª¨ë¦¬ í™•ì¸
import torch
torch.cuda.empty_cache()
print(f"Free: {torch.cuda.mem_get_info()[0]/1e9:.2f} GB")
print(f"Total: {torch.cuda.mem_get_info()[1]/1e9:.2f} GB")

# 15GB ì´ìƒ ì—¬ìœ  ìˆì–´ì•¼ ì•ˆì „
assert torch.cuda.mem_get_info()[0] > 15e9, "Not enough GPU memory!"
```

### 6. ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (16GB GPU ì¤‘ìš”)
```bash
# Training ì¤‘ ë©”ëª¨ë¦¬ ì‹¤ì‹œê°„ í™•ì¸
watch -n 1 nvidia-smi

# Pythonì—ì„œ ë©”ëª¨ë¦¬ ì²´í¬
import torch
print(f"Allocated: {torch.cuda.memory_allocated()/1e9:.2f} GB")
print(f"Reserved: {torch.cuda.memory_reserved()/1e9:.2f} GB")
print(f"Max Allocated: {torch.cuda.max_memory_allocated()/1e9:.2f} GB")

# ì£¼ì˜: 16GB GPUëŠ” 14GB ì´ìƒ ì‚¬ìš© ì‹œ ìœ„í—˜
# ê¶Œì¥: 12GB ì´í•˜ ìœ ì§€
```

---

## ï¿½ğŸ“… Timeline (ì˜ˆìƒ)

- **Week 1**: Phase 1-2 (Data pipeline, Rendering)
- **Week 2**: Phase 3-4 (Network, Training)
- **Week 3**: Phase 5 (Evaluation, Debugging)
- **Week 4**: Experiments, Performance tuning

---

**Last Updated**: 2026ë…„ 2ì›” 16ì¼ (ë²„ê·¸ ìˆ˜ì • ë°˜ì˜)
**Hardware Target**: RTX 4070Ti / RTX 3080 (16GB VRAM)
**Ray Configuration**: 2048 â†’ 16384 (curriculum learning)
**Expected Memory**: ~12GB (16K rays) / ~8-9GB (with AMP)
**Status**: Implementation Phase ğŸ”§ (í•µì‹¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì™„ë£Œ, ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ)

---

## âš ï¸ ë°œê²¬ëœ ë¬¸ì œì  ë° ìˆ˜ì • í•„ìš”ì‚¬í•­

**ê²€í† ì¼**: 2026ë…„ 2ì›” 16ì¼
**ìˆ˜ì •ì¼**: 2026ë…„ 2ì›” 16ì¼

### ë¬¸ì œ 1: GT Projection í˜•íƒœ ë¯¸ëª…ì‹œ â€” âœ… í•´ê²°ë¨

**ë¬¸ì œ**: Loss ê³„ì‚° ì‹œ ground truth X-ray projectionì´ ì–´ë–¤ í˜•íƒœì¸ì§€ ëª…ì‹œë˜ì–´ ìˆì§€ ì•Šì•˜ìŒ.

**ê²°ë¡ **: NAFì˜ `generateData.py`ì—ì„œ `tigre.Ax()`ë¡œ ìƒì„±í•œ projectionì€ **line integral** (âˆ«Î¼ dx)ì´ë©°, ëª¨ë¸ ì¶œë ¥(Î£ Î¼_i Â· Î´t_i)ê³¼ ë™ì¼í•œ ê³µê°„. **ë³€í™˜ ë¶ˆí•„ìš”**.

**ìˆ˜ì •**: `xray_dataset.py` docstringì— GT í˜•íƒœ ëª…ì‹œ ì¶”ê°€.

---

### ë¬¸ì œ 2: `ts` í¬ë§· ë¶ˆì¼ì¹˜ â€” âœ… í•´ê²°ë¨ (CRITICAL BUG FIX)

**ë¬¸ì œ**: CUDA ray marcherì˜ ts í¬ë§·ì€ `[t_position, dt]`ì¸ë°, `batch_composite_rays_xray()`ì—ì„œ `dts = ts[:, 1] - ts[:, 0]` (= dt - t)ìœ¼ë¡œ ì˜ëª» ê³„ì‚°í•˜ê³  ìˆì—ˆìŒ.

**ì˜í–¥**: 
- Training: Beer-Lambert ì ë¶„ì´ ì™„ì „íˆ ì˜ëª»ë¨ (tê°€ ì¦ê°€í• ìˆ˜ë¡ dtsê°€ ìŒìˆ˜)
- Inference: ë™ì¼í•œ ë²„ê·¸ + `rays_t` ë¯¸ì—…ë°ì´íŠ¸ë¡œ ê°™ì€ êµ¬ê°„ ë°˜ë³µ ìƒ˜í”Œë§

**ìˆ˜ì •**:
- `batch_composite_rays_xray()`: `dts = all_ts[:, 1]` (dt ì§ì ‘ ì‚¬ìš©)
- Inference path: `dts = ts[:, 1]` + `rays_t` ì—…ë°ì´íŠ¸ ë¡œì§ + ray ì¢…ë£Œ ë¡œì§ ì¶”ê°€
- í…ŒìŠ¤íŠ¸ ì½”ë“œ: ts ìƒì„±ì„ CUDA `[t_position, dt]` í¬ë§·ìœ¼ë¡œ í†µì¼

---

### ë¬¸ì œ 3: Inference path `rays_t` ë¯¸ì—…ë°ì´íŠ¸ â€” âœ… í•´ê²°ë¨ (CRITICAL BUG FIX)

**ë¬¸ì œ**: `composite_rays()`ê°€ `rays_t` ì—…ë°ì´íŠ¸ì™€ ray ì¢…ë£Œë¥¼ ë‹´ë‹¹í•˜ëŠ”ë°, X-ray ëª¨ë“œì—ì„œ ì´ë¥¼ ê±´ë„ˆë›°ì–´ `rays_t`ê°€ ì˜ì›íˆ ì´ˆê¸°ê°’ì— ë¨¸ë­„.

**ìˆ˜ì •**: X-ray inference ë¸”ë¡ ë’¤ì— ìˆ˜ë™ìœ¼ë¡œ:
- `ts`ì˜ last valid t ê°’ìœ¼ë¡œ `rays_t` ì—…ë°ì´íŠ¸
- n_step ë¯¸ë§Œ ìƒ˜í”Œë§í•œ rayëŠ” `-1`ë¡œ ë§ˆí‚¹í•˜ì—¬ ì¢…ë£Œ

---

### ë¬¸ì œ 4: í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ í†µì¼ â€” âœ… í•´ê²°ë¨

**ë¬¸ì œ**: Plan ë‚´ì—ì„œ `composite_rays_xray()` í˜¸ì¶œ ë°©ì‹ì´ 3ê°€ì§€ë¡œ í˜¼ìš©.

**ìˆ˜ì •**: ZeroRF packed format (`ts: [M, 2]`, `rays: [N, 2]`)ìœ¼ë¡œ í†µì¼ ì™„ë£Œ. ì‹¤ì œ êµ¬í˜„ì€ `batch_composite_rays_xray(sigmas, ts, rays, num_points)` ë‹¨ì¼ ì¸í„°í˜ì´ìŠ¤.

---

### ë¬¸ì œ 5: `xray_mode` íŒŒë¼ë¯¸í„° ì „ë‹¬ ì²´ì¸ â€” âœ… êµ¬í˜„ ì™„ë£Œ

ì „ë‹¬ ê²½ë¡œ (êµ¬í˜„ í™•ì¸ë¨):
```
zerorf.py: xray_mode=True
  â†’ TensorialDecoder.__init__(xray_mode=True)  [decoders.py L140]
    â†’ VolumeRenderer.__init__(xray_mode=True)   [base_volume_renderer.py L90]
    â†’ CommonDecoder.__init__(xray_mode=True)     [decoders.py L148-150]
      â†’ forward(): xray_modeì¼ ë•Œ color network skip
  â†’ VolumeRenderer.forward(): xray_modeì¼ ë•Œ batch_composite_rays_xray ì‚¬ìš©
  â†’ BaseNeRF.loss(): xray_modeì¼ ë•Œ bg_color í•©ì„± skip
  â†’ BaseNeRF.render(): xray_modeì¼ ë•Œ 1ì±„ë„ ì¶œë ¥
  â†’ BaseNeRF.eval_and_viz(): xray_modeì¼ ë•Œ grayscale ì‹œê°í™”
```

---

### ë¬¸ì œ 6: Density Bitfield Threshold â€” ğŸŸ¡ ëª¨ë‹ˆí„°ë§ í•„ìš”

**í˜„ì¬ ì„¤ì •**: `zerorf.py`ì—ì„œ `density_thresh=0.05` (train), `0.01` (test).

NAFì˜ ë°ì´í„°ëŠ” attenuationì„ [0, 1]ë¡œ ì •ê·œí™”í•˜ê³ , ë„¤íŠ¸ì›Œí¬ ì¶œë ¥ì€ `TruncExp()`ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ RGBì™€ ìœ ì‚¬í•œ ìŠ¤ì¼€ì¼. í˜„ì¬ thresholdê°€ ì í•©í•  ìˆ˜ ìˆìœ¼ë‚˜, í•™ìŠµ ê²°ê³¼ë¥¼ ë³´ê³  ì¡°ì • í•„ìš”.

**ì™„í™” ì²˜ë¦¬**: `zerorf.py`ì—ì„œ `occlusion_culling_th=0.0` (X-ray ëª¨ë“œ)ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ occlusion culling ë¹„í™œì„±í™” ì™„ë£Œ.

---

### ë¬¸ì œ 7: Cone-beam â†’ Pinhole ë³€í™˜ â€” âœ… êµ¬í˜„ ì™„ë£Œ, ê²€ì¦ í•„ìš”

`xray_dataset.py`ì— detector offset í¬í•¨í•œ ë³€í™˜ êµ¬í˜„ë¨:
```python
fx = geo.DSD / geo.dDetector[0]
fy = geo.DSD / geo.dDetector[1]
cx = W / 2.0 - geo.offDetector[0] / geo.dDetector[0]
cy = H / 2.0 - geo.offDetector[1] / geo.dDetector[1]
```

NAFì˜ `get_rays()`ì™€ ray ì¼ì¹˜ ê²€ì¦ í…ŒìŠ¤íŠ¸ëŠ” ì•„ì§ ë¯¸ì‘ì„±.

---

### ë¬¸ì œ 8: í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ê²°ì • â€” âœ… í•´ê²°ë¨

`zerorf.py`ì— ì§ì ‘ í†µí•© ì™„ë£Œ (`--dataset xray` í”Œë˜ê·¸ë¡œ ë¶„ê¸°).

---

### ğŸ“‹ ë¬¸ì œ ìƒíƒœ ìš”ì•½

| # | ë¬¸ì œ | ìƒíƒœ | ìˆ˜ì • íŒŒì¼ |
|---|------|------|----------|
| 1 | GT projection í˜•íƒœ | âœ… í•´ê²° | `xray_dataset.py` (docstring) |
| 2 | ts í¬ë§· ë²„ê·¸ (CRITICAL) | âœ… ìˆ˜ì • | `base_volume_renderer.py`, `test_xray_rendering.py` |
| 3 | Inference rays_t ë¯¸ì—…ë°ì´íŠ¸ (CRITICAL) | âœ… ìˆ˜ì • | `base_volume_renderer.py` |
| 4 | í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ í†µì¼ | âœ… í•´ê²° | ì½”ë“œ ì¼ì¹˜ í™•ì¸ |
| 5 | xray_mode ì „ë‹¬ ì²´ì¸ | âœ… êµ¬í˜„ ì™„ë£Œ | ì „ì²´ íŒŒì´í”„ë¼ì¸ í™•ì¸ |
| 6 | Density bitfield threshold | ğŸŸ¡ ëª¨ë‹ˆí„°ë§ | `zerorf.py` (occlusion culling off) |
| 7 | Cone-beam â†’ Pinhole ë³€í™˜ | ğŸŸ¡ ê²€ì¦ í•„ìš” | `xray_dataset.py` |
| 8 | í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ | âœ… í•´ê²° | `zerorf.py` í†µí•© |
